# ğŸ‘‹ Hi, I'm Inesh Reddy Chappidi  
**AI Engineer | LLM Inference Optimization | RAG & Agentic Systems | MLOps**

ğŸ“ Boca Raton, FL | âœ‰ï¸ ineshreddy249@gmail.com | ğŸ”— [LinkedIn](https://www.linkedin.com/in/inesh-reddy)

---

ğŸ“ MS in Computer Science @ **Florida Atlantic University** (Dec 2025)  
ğŸ”¬ Focused on **LLM inference optimization, RAG systems, and multi-agent AI**  
âš™ï¸ Building **production-grade AI systems** with real GPU benchmarks and cloud deployment  
ğŸš€ Open to roles and collaborations in **LLM Inference, AI Infrastructure, and Agentic AI**

---

## ğŸ”§ Core Technologies

**Programming & ML:** Python, PyTorch, C++, Scikit-learn  
**LLM Inference & GPU:** TensorRT-LLM, CUDA 12.x, Speculative Decoding, INT8 / FP16, Fused CUDA Kernels, Flash Attention, Context-FMHA, NVIDIA A100  
**LLMs, RAG & Agents:** Llama-3, Qwen2.5, RAG Pipelines, LangChain, LangGraph, LlamaIndex, MCP, Multi-Agent Orchestration  
**Cloud & Deployment:** FastAPI, Docker, Kubernetes, AWS (ECS, RDS, S3, CloudWatch)  
**Vector Databases:** PostgreSQL + pgvector, ChromaDB, FAISS  

---

## ğŸ“Œ What I Work On

- **LLM inference optimization on NVIDIA GPUs (A100)** using TensorRT-LLM  
- **Speculative Decoding & engine-level performance tuning**  
- **Secure RAG systems for healthcare and enterprise use cases**  
- **Multi-agent AI systems with tool calling and memory**  
- **End-to-end deployment using FastAPI, Docker, and AWS ECS**

---

## ğŸ“ˆ GitHub Stats
<p align="center">
  <img src="https://github-readme-stats.vercel.app/api?username=IneshReddy249&show_icons=true&theme=tokyonight&hide_border=true" height="150">
  <img src="https://github-readme-streak-stats.herokuapp.com?user=IneshReddy249&theme=tokyonight&hide_border=true" height="150">
</p>

---

ğŸ“« **Contact:** ineshreddy249@gmail.com  
ğŸ’¼ **LinkedIn:** https://www.linkedin.com/in/inesh-reddy  

*â€œAI isnâ€™t magic â€” itâ€™s engineering done right.â€*
